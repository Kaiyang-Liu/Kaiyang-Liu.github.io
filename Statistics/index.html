<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Kaiyang Liu</title><meta name="author" content="Kaiyang Liu"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Kaiyang Liu</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/Statistics/"> Statistics</a></li><li class="menus_item"><a class="site-page" href="/MindFlow/"> MindFlow</a></li><li class="menus_item"><a class="site-page" href="/JustBlog/"> JustBlog</a></li><li class="menus_item"><a class="site-page" href="/Gallery/"> Gallery</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/profile.jpg'" alt="avatar"></div><div class="author-discrip"><h3>Kaiyang Liu</h3><p class="author-bio">No Cross, No Crown</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href="https://github.com/Kaiyang-Liu/" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://www.linkedin.com/in/kaiyang-liu-51541116a/" target="_blank"><i class="fab fa-linkedin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="mailto:louisliu0614@gmail.com" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i></a></li></ul></div></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">Statistics</h2><article><p><img src="/images/cover.jpg"></p>
<p><em><strong>System rebuilding…</strong></em></p>
<p>.  </p>
<h1 id="Content"><a href="#Content" class="headerlink" title="Content"></a><strong>Content</strong></h1><h2 id="1-Machine-Learning"><a href="#1-Machine-Learning" class="headerlink" title="1. Machine Learning"></a><em><strong>1. Machine Learning</strong></em></h2><h2 id="2-Introduction-to-Deep-Learning"><a href="#2-Introduction-to-Deep-Learning" class="headerlink" title="2. Introduction to Deep Learning"></a><em><strong>2. Introduction to Deep Learning</strong></em></h2><h2 id="3-Statistical-Foundation-of-Data-Science-A-Guide"><a href="#3-Statistical-Foundation-of-Data-Science-A-Guide" class="headerlink" title="3. Statistical Foundation of Data Science (A Guide)"></a><em><strong>3. Statistical Foundation of Data Science (A Guide)</strong></em></h2><p>.<br>.<br>.</p>
<h1 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a><em><strong>Machine Learning</strong></em></h1><hr>
<p><em><a target="_blank" rel="noopener" href="https://github.com/Kaiyang-Liu/notebook/blob/main/Data%20Mining/QF%20Notes%20-%20PCA.pdf">Principal Component Analysis (PCA)</a></em></p>
<p><em><a target="_blank" rel="noopener" href="https://github.com/Kaiyang-Liu/notebook/blob/main/Data%20Mining/QF%20Notes%20-%20Kernel%20PCA.pdf">Kernel Principal Component Analysis (Kernel PCA)</a></em></p>
<p><em><a target="_blank" rel="noopener" href="https://github.com/Kaiyang-Liu/notebook/blob/main/Data%20Mining/QF%20Notes%20-%20K-means.pdf">K-means</a></em></p>
<p><em><a target="_blank" rel="noopener" href="https://github.com/Kaiyang-Liu/notebook/blob/main/Data%20Mining/QF%20Notes%20-%20Gaussian%20Mixture%20Model.pdf">Gaussian Mixture Model</a></em></p>
<hr>
<p><em>Tree-Based Methods</em></p>
<p><em><a target="_blank" rel="noopener" href="https://github.com/Kaiyang-Liu/notebook/blob/main/Data%20Mining/Descision%20Tree.pdf">Decision Tree</a></em></p>
<p><em>Gradient Boost Decision Tree</em></p>
<p><em>XGBoost</em></p>
<p><em>LightGBM</em></p>
<hr>
<p><em>Incoming Topics…</em></p>
<p><em>Logistic Regression</em></p>
<p><em>K-Nearest Neighbor (KNN)</em></p>
<p><em>Support Vector Machine (SVM)</em></p>
<p>.<br>.<br>.</p>
<h1 id="Introduction-to-Deep-Learning"><a href="#Introduction-to-Deep-Learning" class="headerlink" title="Introduction to Deep Learning"></a><em><strong>Introduction to Deep Learning</strong></em></h1><hr>
<p><em>Description: A simple graph demonstrating how MLP, RNN (LSTM, GRU) work, including the mathematical derivation of feedforward, backpropagation, and backpropagation through time.</em></p>
<p><em><a target="_blank" rel="noopener" href="https://github.com/Kaiyang-Liu/notebook/blob/main/Deep%20Learning/MLP.md">MLP (Multiple Layer Perceptron)</a></em></p>
<p><em><a target="_blank" rel="noopener" href="https://github.com/Kaiyang-Liu/notebook/blob/main/Deep%20Learning/RNN.md">RNN (Recurrent Neural Network)</a></em></p>
<p><em><a target="_blank" rel="noopener" href="https://github.com/Kaiyang-Liu/notebook/blob/main/Deep%20Learning/RNN.md">LSTM (Long Short-Term Memory) &amp; GRU (Gate Recurrent Unit)</a></em>  </p>
<p>.<br>.<br>.</p>
<h1 id="Statistical-Foundation-of-Data-Science-A-Guide"><a href="#Statistical-Foundation-of-Data-Science-A-Guide" class="headerlink" title="Statistical Foundation of Data Science (A Guide)"></a><em><strong>Statistical Foundation of Data Science (A Guide)</strong></em></h1><hr>
<h2 id="Set-1-Probability-theory-and-mathematical-statistics-I"><a href="#Set-1-Probability-theory-and-mathematical-statistics-I" class="headerlink" title="Set 1  Probability theory and mathematical statistics (I)"></a><em><strong>Set 1  Probability theory and mathematical statistics (I)</strong></em></h2><ul>
<li><em>Discrete Random Variables</em></li>
<li><em>Continuous Random Variables</em></li>
<li><em>Functions of a Random Variable</em></li>
<li><em>Joint Distributions</em></li>
<li><em>Independent Random Variables</em></li>
<li><em>Conditional Distributions</em></li>
<li><em>Functions of Jointly Distributed Random Variables</em></li>
<li><em>Extrema and Order Statistics</em></li>
<li><em>Expected Values</em></li>
<li><em>Limit Theorems</em></li>
</ul>
<h2 id="Set-2-Probability-theory-and-mathematical-statistics-II"><a href="#Set-2-Probability-theory-and-mathematical-statistics-II" class="headerlink" title="Set 2  Probability theory and mathematical statistics (II)"></a><em><strong>Set 2  Probability theory and mathematical statistics (II)</strong></em></h2><ul>
<li><em>Examples &amp; Reasons for Fitting Distribution</em></li>
<li><em>Parameter Estimation</em></li>
<li><em>The Method of Moments</em></li>
<li><em>The Method of Maximum Likelihood</em></li>
<li><em>Maximum Likelihood Estimates of Multinomial Cell Probabilities</em></li>
<li><em>Large Sample Theory for Maximum Likelihood Estimates</em></li>
<li><em>Confidence Intervals from Maximum Likelihood Estimates</em></li>
<li><em>Efficiency and the Cramer-Rao Lower Bound</em></li>
<li><em>Ancillary Statistics</em></li>
<li><em>Sufficient Statistics</em></li>
<li><em>A Factorization Theorem</em></li>
<li><em>The Rao-Blackwell Theorem</em></li>
<li><em>Delta method</em></li>
</ul>
<h2 id="Set-3-The-Bayesian-Approach-to-Parameter-Estimation"><a href="#Set-3-The-Bayesian-Approach-to-Parameter-Estimation" class="headerlink" title="Set 3 The Bayesian Approach to Parameter Estimation"></a><em><strong>Set 3 The Bayesian Approach to Parameter Estimation</strong></em></h2><ul>
<li><em>Example of Bayesian Inference</em></li>
<li><em>Bayesian Point Estimation and Interval Estimation</em></li>
<li><em>Large Sample Normal Approximation to the Posterior</em></li>
<li><em>Computational Aspects: Gibbs Sampling, Markov Chain Monte Carlo</em></li>
<li><em>Bayesian Testing Procedures</em></li>
</ul>
<h2 id="Set-4-Testing-Hypotheses-and-Assessing-Goodness-of-Fit"><a href="#Set-4-Testing-Hypotheses-and-Assessing-Goodness-of-Fit" class="headerlink" title="Set 4 Testing Hypotheses and Assessing Goodness of Fit"></a><em><strong>Set 4 Testing Hypotheses and Assessing Goodness of Fit</strong></em></h2><ul>
<li><em>Basics of Hypotheses Testing</em></li>
<li><em>The Neyman-Pearson Paradigm</em></li>
<li><em>Specification of the Significance Level and the Concept of a p-value</em></li>
<li><em>Uniformly Most Powerful Tests</em></li>
<li><em>The Duality of Confidence Intervals and Hypothesis Tests</em></li>
<li><em>Generalized Likelihood Ratio Tests</em></li>
<li><em>Likelihood Ratio Tests for the Multinomial Distribution</em></li>
<li><em>The Poisson Dispersion Test</em></li>
<li><em>Probability Plots</em></li>
<li><em>Tests for Normality</em></li>
</ul>
<h2 id="Set-5-Nonparametric-Statistics"><a href="#Set-5-Nonparametric-Statistics" class="headerlink" title="Set 5 Nonparametric Statistics"></a><em><strong>Set 5 Nonparametric Statistics</strong></em></h2><ul>
<li>*Nonparametric hypothesis testing:*<br> <em>Permutation testing, Rank-based tests: Mann-Whitney Test, Wilcoxon Rank Sum Test</em></li>
<li><em>Empirical distributions and the plug-in principle</em><br> <em>Empirical CDF, empirical distributions, convergence theorems, Monte Carlo integration</em></li>
<li><em>Density estimation</em><br> <em>Histogram estimators, Kernel density estimators</em></li>
<li><em>Nonparametric regression</em><br> *Definitions, Linear regression: Regressograms, Kernel regression: Nadaraya-Watson kernel regression,*<br> <em>Cross-validation, Curse of dimensionality</em></li>
</ul>
<h2 id="Set-6-Bootstrap"><a href="#Set-6-Bootstrap" class="headerlink" title="Set 6 Bootstrap"></a><em><strong>Set 6 Bootstrap</strong></em></h2><ul>
<li><em>Motivation for bootstrap</em></li>
<li><em>Bootstrap basics</em></li>
<li><em>Bootstrap confidence intervals</em></li>
<li><em>Other uses of bootstrap</em></li>
<li><em>Quantifying uncertainty more generally</em></li>
</ul>
<h2 id="Set-7-Monte-Carlo-Sampling"><a href="#Set-7-Monte-Carlo-Sampling" class="headerlink" title="Set 7 Monte Carlo Sampling"></a><em><strong>Set 7 Monte Carlo Sampling</strong></em></h2><ul>
<li><em>Motivation from Bayesian inference</em></li>
<li><em>Monte Carlo Methods:</em></li>
<li><em>Direct Sampling</em></li>
<li><em>Rejection Sampling</em></li>
<li><em>Importance Sampling</em></li>
<li><em>Markov Chain Monte Carlo</em></li>
<li>Cont.</li>
</ul>
<p>*<a target="_blank" rel="noopener" href="https://github.com/yanshuotan/st5201x">Github Resource from Set 4-7</a>*<br>.<br>.<br>.</p>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/Statistics/"> Statistics</a></li><li class="nav_item"><a class="nav-page" href="/MindFlow/"> MindFlow</a></li><li class="nav_item"><a class="nav-page" href="/JustBlog/"> JustBlog</a></li><li class="nav_item"><a class="nav-page" href="/Gallery/"> Gallery</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2020 - 2024 by Kaiyang Liu</div><div class="theme-info">Powered by <a target="_blank" href="https://hexo.io" rel="nofollow noopener">Hexo</a> & <a target="_blank" href="https://github.com/PhosphorW/hexo-theme-academia" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>